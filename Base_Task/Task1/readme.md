# 书生·浦语大模型全年链路开源体系

### 大模型的发展之路和书生·浦语大模型的开源历程

![pic1](./pic/1.png)

自21世纪深度学习理论的突破以来，各类专用模型不断涌现并展现出出色的表现。针对特定的任务，一个模型解决一个问题的专用模型引发了人们的广泛关注。同时，让一个模型能够应对多种任务、多种模态的通过用大模型逐渐成为人工智能的发展趋势。

![pic2](./pic/2.png)

InternLM2开源模型有7B和20B两种规格，同时每个规格包含三个模型版本：
 - InternLM2-Base：高质量和具有很强可塑性的模型基座，是模型进行深度领域适配的高质量起点。
 - InternLM2：在Base的基础上，对多个能力方向进行了优化，在评测中成绩优异，同时保持了很好的通用语言能力，是推荐的在大部分应用中考虑选用的优秀基座模型。
 - InternLM2-Chat：在Base的基础上经过SFT和RLHF，面向对话交互进行了优化，具有很好的指令遵循、共情聊天和调用工具的能力。

**InternLM2回归语言建模的本质，使用新一代数据清洗过滤技术**
通过多维度数据价值评估、高质量语料驱动的数据富集和有针对性地数据补齐，提升模型下游任务的性能。

InternLM2的主要亮点：

 - 超长上下文：模型在20万token上下文中几乎完美的实现"大海捞针"
 - 综合性能全面提升：推理、数学、代码提升显著
 - 优秀的对话和创作体验：精准指令跟随、丰富的结构化创作
 - 工具调用能力整体提升：可靠支持工具多轮调用，复杂智能体搭建
 - 突出的数理能力和实用的数据分析功能：强大的内生计算能力，加入代码解释后能力进一步提升
